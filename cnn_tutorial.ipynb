{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks Tutorial\n",
    "\n",
    "In this notebook, you will:\n",
    "\n",
    "- Implement helper functions that you will use when implementing a PyTorch model\n",
    "- Implement a fully functioning ConvNet using PyTorch \n",
    "\n",
    "**After this assignment you will be able to:**\n",
    "\n",
    "- Build and train a ConvNet in PyTorch for a classification problem "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Outline of the Assignment\n",
    "\n",
    "You will be implementing the building blocks of a convolutional neural network! Each function you will implement will have detailed instructions that will walk you through the steps needed:\n",
    "\n",
    "- Convolution functions\n",
    "\n",
    "- Pooling functions\n",
    "\n",
    "    \n",
    "In this next notebook, you will use the PyTorch equivalents of these functions to build the following model:\n",
    "\n",
    "<img src=\"images/model.png\" style=\"width:800px;height:300px;\">\n",
    "\n",
    "**Note** that for every forward function, there is its corresponding backward equivalent. Hence, at every step of your forward module you will store some parameters in a cache. These parameters are used to compute gradients during backpropagation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Convolutional Neural Networks\n",
    "\n",
    "Although programming frameworks make convolutions easy to use, they remain one of the hardest concepts to understand in Deep Learning. A convolution layer transforms an input volume into an output volume of different size, as shown below. \n",
    "\n",
    "<img src=\"images/conv_nn.png\" style=\"width:350px;height:200px;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Zero-Padding\n",
    "\n",
    "Zero-padding adds zeros around the border of an image:\n",
    "\n",
    "<img src=\"images/PAD.png\" style=\"width:600px;height:400px;\">\n",
    "<caption><center> <u> <font color='purple'> **Figure 1** </u><font color='purple'>  : **Zero-Padding**<br> Image (3 channels, RGB) with a padding of 2. </center></caption>\n",
    "\n",
    "The main benefits of padding are the following:\n",
    "\n",
    "- It allows you to use a CONV layer without necessarily shrinking the height and width of the volumes. This is important for building deeper networks, since otherwise the height/width would shrink as you go to deeper layers. An important special case is the \"same\" convolution, in which the height/width is exactly preserved after one layer. \n",
    "\n",
    "- It helps us keep more of the information at the border of an image. Without padding, very few values at the next layer would be affected by pixels as the edges of an image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Single step of convolution \n",
    "\n",
    "In this part, implement a single step of convolution, in which you apply the filter to a single position of the input. This will be used to build a convolutional unit, which: \n",
    "\n",
    "- Takes an input volume \n",
    "- Applies a filter at every position of the input\n",
    "- Outputs another volume (usually of different size)\n",
    "\n",
    "<img src=\"images/Convolution_schematic.gif\" style=\"width:500px;\">\n",
    "<caption><center> <u> <font color='purple'> **Figure 2** </u><font color='purple'>  : **Convolution operation**<br> with a filter of 3x3 and a stride of 1 (stride = amount you move the window each time you slide) </center></caption>\n",
    "\n",
    "In a computer vision application, each value in the matrix on the left corresponds to a single pixel value, and we convolve a 3x3 filter with the image by multiplying its values element-wise with the original matrix, then summing them up and adding a bias. In this first step of the exercise, you will implement a single step of convolution, corresponding to applying a filter to just one of the positions to get a single real-valued output. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a running demo of a CONV layer. Since 3D volumes are hard to visualize, all the volumes (the input volume (in blue), the weight volumes (in red), the output volume (in green)) are visualized with each depth slice stacked in rows. The input volume is of size W1=5, H1=5, D1=3, we have two filters of size 3×3, and they are applied with a stride of 2. \n",
    "<img src=\"images/mulinput.gif\" style=\"width:600px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference：\n",
    "<a href=\"http://cs231n.github.io/convolutional-networks/\">http://cs231n.github.io/convolutional-networks/</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - Convolutional Neural Networks - Forward pass\n",
    "\n",
    "In the forward pass, you will take many filters and convolve them on the input. Each 'convolution' gives you a 2D matrix output. You will then stack these outputs to get a 3D volume: \n",
    "\n",
    "<center>\n",
    "<video width=\"620\" height=\"440\" src=\"images/conv_kiank.mp4\" type=\"video/mp4\" controls>\n",
    "</video>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Pooling layer \n",
    "\n",
    "The pooling (POOL) layer reduces the height and width of the input. It helps reduce computation, as well as helps make feature detectors more invariant to its position in the input. The two types of pooling layers are: \n",
    "\n",
    "- Max-pooling layer: slides an ($f, f$) window over the input and stores the max value of the window in the output.\n",
    "\n",
    "- Average-pooling layer: slides an ($f, f$) window over the input and stores the average value of the window in the output.\n",
    "\n",
    "<table>\n",
    "<td>\n",
    "<img src=\"images/max_pool1.png\" style=\"width:500px;height:300px;\">\n",
    "<td>\n",
    "\n",
    "<td>\n",
    "<img src=\"images/a_pool.png\" style=\"width:500px;height:300px;\">\n",
    "<td>\n",
    "</table>\n",
    "\n",
    "These pooling layers have no parameters for backpropagation to train. However, they have hyperparameters such as the window size $f$. This specifies the height and width of the fxf window you would compute a max or average over. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ipynb` notebook and slides associated with <a href=\"http://deeplearning.ai\">deeplearning.ai</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - PyTorch model\n",
    "\n",
    "Most practical applications of deep learning today are built using programming frameworks, which have many built-in functions you can simply call. \n",
    "\n",
    "As usual, we will start by loading in the packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import datetime\n",
    "import torch\n",
    "import torchtext.data as data\n",
    "import torchtext.datasets as datasets\n",
    "#import mydatasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#dataset\n",
    "import re\n",
    "import random\n",
    "import tarfile\n",
    "import urllib\n",
    "from torchtext import data\n",
    "\n",
    "#model\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "#train\n",
    "import sys\n",
    "import torch.autograd as autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to add parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial learning rate\n",
    "lr = 0.001\n",
    "#number of epochs for train\n",
    "epochs =  50\n",
    "#batch size for training\n",
    "batch_size = 64\n",
    "#how many steps to wait before logging training status\n",
    "log_interval = 1\n",
    "#how many steps to wait before testing\n",
    "test_interval=50\n",
    "#iteration numbers to stop without performance increasing\n",
    "early_stop = 1000\n",
    "# data \n",
    "#shuffle the data every epoch\n",
    "shuffle = False\n",
    "# model\n",
    "#the probability for dropout\n",
    "dropout = 0.5\n",
    "#constraint of parameters\n",
    "max_norm = 3.0\n",
    "#number of embedding dimension\n",
    "embed_dim = 128\n",
    "#number of each kind of kernel\n",
    "kernel_num =100\n",
    "#comma-separated kernel size to use for convolution\n",
    "kernel_sizes = '3,4,5'\n",
    "#fix the embedding\n",
    "static = False\n",
    "# device\n",
    "#device to use for iterate data, -1 mean cpu [default: -1]\n",
    "device = -1\n",
    "#disable the gpu\n",
    "no_cuda = False\n",
    "# option\n",
    "#train or test\n",
    "test = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Movie Review data from Rotten Tomatoes**\n",
    "- Classify that the review is positive/negative\n",
    "- Statistics\n",
    "<img src=\"images/mrdataset.png\" style=\"width:700px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing on text**\n",
    "- Remove special symbol by regular expression\n",
    "- Split sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to load the \"movie review\" dataset you are going to use.\n",
    "\n",
    "As a reminder,the Movie Review data from Rotten Tomatoes classify that the review is positive/negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MR(data.Dataset):\n",
    "\n",
    "    @staticmethod\n",
    "    def sort_key(ex):\n",
    "        return len(ex.text)\n",
    "\n",
    "    def __init__(self, text_field, label_field, path=None, examples=None, **kwargs):\n",
    "       \n",
    "        def clean_str(string):\n",
    "            \"\"\"\n",
    "            Tokenization/string cleaning for all datasets except for SST.\n",
    "            Original taken from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
    "            \"\"\"\n",
    "            string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "            string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "            string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "            string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "            string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "            string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "            string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "            string = re.sub(r\",\", \" , \", string)\n",
    "            string = re.sub(r\"!\", \" ! \", string)\n",
    "            string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "            string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "            string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "            string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "            return string.strip()\n",
    "\n",
    "        text_field.preprocessing = data.Pipeline(clean_str)\n",
    "        fields = [('text', text_field), ('label', label_field)]\n",
    "\n",
    "        if examples is None:\n",
    "            path = self.dirname if path is None else path\n",
    "            examples = []\n",
    "            with open(os.path.join(path, 'rt-polarity.neg'), errors='ignore') as f:\n",
    "                examples += [\n",
    "                    data.Example.fromlist([line, 'negative'], fields) for line in f]\n",
    "            with open(os.path.join(path, 'rt-polarity.pos'), errors='ignore') as f:\n",
    "                examples += [\n",
    "                    data.Example.fromlist([line, 'positive'], fields) for line in f]\n",
    "        super(MR, self).__init__(examples, fields, **kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def splits(cls, text_field, label_field, dev_ratio=.1, shuffle=True, **kwargs):\n",
    "        \"\"\"Create dataset objects for splits of the MR dataset.\n",
    "\n",
    "        Arguments:\n",
    "            text_field: The field that will be used for the sentence.\n",
    "            label_field: The field that will be used for label data.\n",
    "            dev_ratio: The ratio that will be used to get split validation dataset.\n",
    "            shuffle: Whether to shuffle the data before split.\n",
    "\n",
    "        \"\"\"\n",
    "        path = \"./rt-polaritydata/\"\n",
    "        examples = cls(text_field, label_field, path=path, **kwargs).examples\n",
    "        if shuffle: random.shuffle(examples)\n",
    "        dev_index = -1 * int(dev_ratio*len(examples))\n",
    "\n",
    "        return (cls(text_field, label_field, examples=examples[:dev_index]),\n",
    "                cls(text_field, label_field, examples=examples[dev_index:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load MR dataset\n",
    "def mr(text_field, label_field, **kargs):\n",
    "    train_data, dev_data = MR.splits(text_field, label_field)\n",
    "    text_field.build_vocab(train_data, dev_data)\n",
    "    label_field.build_vocab(train_data, dev_data)\n",
    "    train_iter, dev_iter = data.Iterator.splits(\n",
    "                                (train_data, dev_data), \n",
    "                                batch_sizes=(batch_size, len(dev_data)),\n",
    "                                **kargs)\n",
    "    return train_iter, dev_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_field = data.Field(lower=True)\n",
    "label_field = data.Field(sequential=False)\n",
    "train_iter, dev_iter = mr(text_field, label_field, device=-1, repeat=False)\n",
    "# train_iter, dev_iter, test_iter = sst(text_field, label_field, device=-1, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_num = len(text_field.vocab)\n",
    "class_num = len(label_field.vocab) - 1\n",
    "cuda = (not no_cuda) and torch.cuda.is_available(); del no_cuda\n",
    "kernel_sizes = [int(k) for k in kernel_sizes.split(',')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "The network we will build in this post looks roughly as follows:\n",
    "\n",
    "<img src=\"images/textcnn.png\" style=\"height:300px;\">\n",
    "\n",
    "The first layers embeds words into low-dimensional vectors. The next layer performs convolutions over the embedded word vectors using multiple filter sizes. For example, sliding over 3, 4 or 5 words at a time. Next, we max-pool the result of the convolutional layer into a long feature vector, add dropout regularization, and classify the result using a softmax layer, and we will not used pre-trained word2vec vectors for our word embeddings. Instead, we learn embeddings from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Text(nn.Module):\n",
    "    \n",
    "    def __init__(self, lr,epochs,batch_size,log_interval,test_interval,early_stop,shuffle,dropout\\\n",
    "                 ,max_norm,embed_dim,kernel_num,kernel_sizes,static,device,no_cuda,test):\n",
    "        super(CNN_Text, self).__init__()\n",
    "        \n",
    "        V = embed_num\n",
    "        D = embed_dim\n",
    "        C = class_num\n",
    "        Ci = 1\n",
    "        Co = kernel_num\n",
    "        Ks = kernel_sizes\n",
    "        \n",
    "        self.embed = nn.Embedding(V, D)\n",
    "        # self.convs1 = [nn.Conv2d(Ci, Co, (K, D)) for K in Ks]\n",
    "        self.convs1 = nn.ModuleList([nn.Conv2d(Ci, Co, (K, D)) for K in Ks])\n",
    "        '''\n",
    "        self.conv13 = nn.Conv2d(Ci, Co, (3, D))\n",
    "        self.conv14 = nn.Conv2d(Ci, Co, (4, D))\n",
    "        self.conv15 = nn.Conv2d(Ci, Co, (5, D))\n",
    "        '''\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(len(Ks)*Co, C)\n",
    "\n",
    "    def conv_and_pool(self, x, conv):\n",
    "        x = F.relu(conv(x)).squeeze(3)  # (N, Co, W)\n",
    "        x = F.max_pool1d(x, x.size(2)).squeeze(2)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)  # (N, W, D)\n",
    "        \n",
    "        if static:\n",
    "            x = Variable(x)\n",
    "\n",
    "        x = x.unsqueeze(1)  # (N, Ci, W, D)\n",
    "\n",
    "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1]  # [(N, Co, W), ...]*len(Ks)\n",
    "\n",
    "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  # [(N, Co), ...]*len(Ks)\n",
    "\n",
    "        x = torch.cat(x, 1)\n",
    "\n",
    "        '''\n",
    "        x1 = self.conv_and_pool(x,self.conv13) #(N,Co)\n",
    "        x2 = self.conv_and_pool(x,self.conv14) #(N,Co)\n",
    "        x3 = self.conv_and_pool(x,self.conv15) #(N,Co)\n",
    "        x = torch.cat((x1, x2, x3), 1) # (N,len(Ks)*Co)\n",
    "        '''\n",
    "        x = self.dropout(x)  # (N, len(Ks)*Co)\n",
    "        logit = self.fc1(x)  # (N, C)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_iter, dev_iter, model, lr,epochs,batch_size,log_interval,test_interval,early_stop,shuffle,dropout\\\n",
    "                 ,max_norm,embed_dim,kernel_num,kernel_sizes,static,device,no_cuda,test):\n",
    "    if cuda:\n",
    "        model.cuda()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    steps = 0\n",
    "    best_acc = 0\n",
    "    last_step = 0\n",
    "    accuracies = []\n",
    "    model.train()\n",
    "    for epoch in range(1, epochs+1):\n",
    "        for batch in train_iter:\n",
    "            feature, target = batch.text, batch.label\n",
    "            feature.data.t_(), target.data.sub_(1)  # batch first, index align\n",
    "            if cuda:\n",
    "                feature, target = feature.cuda(), target.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logit = model(feature)\n",
    "\n",
    "            #print('logit vector', logit.size())\n",
    "            #print('target vector', target.size())\n",
    "            loss = F.cross_entropy(logit, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            steps += 1\n",
    "            if steps % log_interval == 0:\n",
    "                corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
    "                accuracy = 100.0 * corrects/batch.batch_size\n",
    "                sys.stdout.write(\n",
    "                    '\\rBatch[{}] - loss: {:.6f}  acc: {:.4f}%({}/{})'.format(steps, \n",
    "                                                                             loss.data[0], \n",
    "                                                                             accuracy,\n",
    "                                                                             corrects,\n",
    "                                                                             batch.batch_size))\n",
    "            if steps % test_interval == 0:\n",
    "                dev_acc = eval(dev_iter, model, cuda)\n",
    "                accuracies.append(dev_acc)\n",
    "                if dev_acc > best_acc:\n",
    "                    best_acc = dev_acc\n",
    "                    last_step = steps\n",
    "                else:\n",
    "                    if steps - last_step >= early_stop:\n",
    "                        print('early stop by {} steps.'.format(early_stop))\n",
    "\n",
    "                \n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(accuracies))\n",
    "    plt.ylabel('acc')\n",
    "    plt.xlabel('iterations')\n",
    "    plt.title(\"Learning rate =\" + str(lr))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def eval(data_iter, model, cuda):\n",
    "    model.eval()\n",
    "    corrects, avg_loss = 0, 0\n",
    "    for batch in data_iter:\n",
    "        feature, target = batch.text, batch.label\n",
    "        feature.data.t_(), target.data.sub_(1)  # batch first, index align\n",
    "        if cuda:\n",
    "            feature, target = feature.cuda(), target.cuda()\n",
    "\n",
    "        logit = model(feature)\n",
    "        loss = F.cross_entropy(logit, target, size_average=False)\n",
    "\n",
    "        avg_loss += loss.data[0]\n",
    "        corrects += (torch.max(logit, 1)\n",
    "                     [1].view(target.size()).data == target.data).sum()\n",
    "        \n",
    "    size = len(data_iter.dataset)\n",
    "    avg_loss /= size\n",
    "    accuracy = 100.0 * corrects/size\n",
    "    print('\\nEvaluation - loss: {:.6f}  acc: {:.4f}%({}/{}) \\n'.format(avg_loss, \n",
    "                                                                       accuracy, \n",
    "                                                                       corrects, \n",
    "                                                                       size))\n",
    "    \n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_cuda = False\n",
    "cnn = CNN_Text(lr,epochs,batch_size,log_interval,test_interval,early_stop,shuffle,dropout\\\n",
    "               ,max_norm,embed_dim,kernel_num,kernel_sizes,static,device,no_cuda,test)\n",
    "\n",
    "if cuda:\n",
    "    torch.cuda.set_device(device)\n",
    "    cnn = cnn.cuda()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_Text(\n",
      "  (embed): Embedding(21114, 128)\n",
      "  (convs1): ModuleList(\n",
      "    (0): Conv2d(1, 100, kernel_size=(3, 128), stride=(1, 1))\n",
      "    (1): Conv2d(1, 100, kernel_size=(4, 128), stride=(1, 1))\n",
      "    (2): Conv2d(1, 100, kernel_size=(5, 128), stride=(1, 1))\n",
      "  )\n",
      "  (dropout): Dropout(p=0.5)\n",
      "  (fc1): Linear(in_features=300, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    train(train_iter, dev_iter, cnn, lr,epochs,batch_size,log_interval,test_interval,early_stop,shuffle,dropout\\\n",
    "             ,max_norm,embed_dim,kernel_num,kernel_sizes,static,device,no_cuda,test)\n",
    "except KeyboardInterrupt:\n",
    "    print('\\n' + '-' * 89)\n",
    "    print('Exiting from training early')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: <a href=\"https://github.com/Shawn1993/cnn-text-classification-pytorch\">https://github.com/Shawn1993/cnn-text-classification-pytorch</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
